# 1. PUTTY 실행

windows putty 검색 
-> load 
-> lab04
-> cd /opt/spark
-> pyspark

# 2. SPARK 살펴보기

## 1 ) 간단한 책 예제( p. 71~ )

![image-20200210112214902](images/image-20200210112214902.png)

```sql
1 ) 데이터로부터 DataFrame 생성
myRange = spark.range(1000).toDF("number")

2 ) 트랜스포메이션 연산, 새로운 DataFrame으로 결과 생성
divisBy2 = myRange.where("number %2 = 0")

3 ) 액션 연산
divisBy2.count()
# 결과 : 500
```

## 2 ) 예제를 풀어보자

### a. 데이터 예제를 다운받아보자

* 미국 교통통계국의 항공운항 데이터 사용 (p.77)

* 고유 폴더 접속(?????)

![image-20200210112906273](images/image-20200210112906273.png)

```sql
cd ~
mkdir data
ls -al /home/lab04
```



* github에서 예제 다운로드 (2015)

  https://github.com/FVBros/Spark-The-Definitive-Guide/blob/master/data/flight-data/csv/2015-summary.csv

  ![image-20200210113347305](images/image-20200210113347305.png)

  2015 -> raw -> ctrl + a -> 메모장 -> csv file로 저장(2015_summary.csv)

### b. download받은 예제를 jupyter notebook에 upload하자

* jupyter notebook 에 들어가자

  ![image-20200210114016559](images/image-20200210114016559.png)

  ```sql
  conda activate
  jupyter-notebook --ip=0.0.0.0 --no-browser --port=8893
  ```

  ![image-20200210114059440](images/image-20200210114059440.png)

복사(오른쪽 마우스)해서 chrome에 붙여넣기 ->  jupyter notebook 이 로드 되면

* data folder에 2015_summary.csv를 upload

![image-20200210114306930](images/image-20200210114306930.png)



### c. 실행해보자

```sql
1 ) directory 변경
cd /opt/spark
pyspark

2 ) file load
flightData2015 = spark.read.option("inferSchema","true").option("header","true").csv("/home/lab04/data/2015_summary.csv")

3 ) rows확인
flightData2015.take(3)

4 ) sort -> 실행 계획 확인
sort : 데이터에 아무런 변화도 일어나지 않는다
explain : 실행 계획을 알려준다
flightData2015.sort("count").explain()
-- 현재 local 환경에서 실행하고 있기 때문에 standalone형태이고, partion = 1 이다.
```

![image-20200210122929392](images/image-20200210122929392.png)

* 액션 호출 : partition이 한 개이므로 [ ]가 한 개이다

  ![image-20200210132233285](images/image-20200210132233285.png)



## 3 ) DataFrame 과 SQL

: SparkSQL은 sql로 처리하거나 DataFrame을 이용해서 구조적 API의 메서드를 이용해서 SQL 방식으로 처리하려면, 테이블 또는 임시테이블(VIEW)에 등록해야 한다.

```sql
flightData2015 = spark.read.option("inferSchema","true").option("header","true").csv("/home/lab04/data/2015_summary.csv")

-- 방법 1 )
flightData2015.createOrReplaceTempView("flight_data_2015")
sqlWay = spark.sql("""
                  select dest_country_name, count(1)
                  from flight_data_2015
                  group by dest_country_name
                  """)
sqlWay.explain()
                  
-- 방법 2 )
dataFrameWay = flightData2015.groupby("DEST_COUNTRY_NAME").count()
dataFrameWay.explain()

-- 방법 3 )
from pyspark.sql.functions import max
flightData2015.select(max("count")).take(1)
```

* 방법 1 

![image-20200210133259095](images/image-20200210133259095.png)

* 방법 2

![image-20200210133418385](images/image-20200210133418385.png)

* 방법 3

![image-20200210133446951](images/image-20200210133446951.png)



# filezilla

: 편집 -> 설정 -> 키 파일 추가 -> ppk 파일 찾기

![image-20200210141313039](images/image-20200210141313039.png)

: 파일 -> 사이트 관리자 -> new site -> EC2확인 -> 호스트 : ec2-52-79-46-13.150.ap northeast 2.compute.amazonaws.com -> 사용자 : shpark_ml_b -> 비밀번호 : ******** -> 연결

![image-20200210142424319](images/image-20200210142424319.png)

서버 연결이 안된다

호스트 : sftp://52.79.46.13 -> 사용자명 : lab04 -> 빠른 연결

![image-20200210142511320](images/image-20200210142511320.png)

