# 1. 차원 축소를 해야 하는 이유(목적)

1 ) 데이터 시각화 가능 -> 데이터 패턴 이해 용이

2 ) 노이즈 제거

3 ) 메모리 절약 -> 모델 성능 개선



# 2. 차원 축소 method(방법)

1 ) 주성분분석(PCA) : 데이터 특성 값을 갖고 class를 구분하는데 두드러진 특성을 알아낼 수 있다

: 데이터 집합에 대해 공분산 행렬 구함 -> 공분산 행렬로부터 고유값과 고유벡터 계산 -> 고유값 목록에서 값이 높은 k개의 인덱스를 구함

: 정방행렬에만 사용 가능

: PCA는 데이터 압축, 얼굴 인식 기능 등에 활용된다



2 ) LDA(선형 판별 분석) : 클래스를 최대한 분리하는 성분을 축으로 차원 축소



3 ) SVD(특이값 분해)를 이용한 차원 축소

: PCA와 비슷한데 행렬을 대각화하는 방법으로 정방행렬이 아니어도 m * n 행렬에 대해 적용 가능하다 

: 직교하는 벡터 집합에 대해서 선형 변환을 한다 -> 크기는 변하지만 여전히 직교가 되는 부분집합을 찾아서 -> 얘를 차원축소한다

: SVD는 데이터 압축에 사용되고, 유사도 분석에 많이 활용된다

* TSVD : 희소특성행렬에 적용가능



4 ) NMF(비음수 행렬 인수분해) : 비지도학습 알고리즘 

: 음수가 아닌 특성과 계수 값을 찾음

: 주성분 계수가 양수(0보다 크거나 같아야 한다)

: 음수가 아닌 특성들에 대해서 가중치의 합으로 데이터를 분해

: 여러 데이터 특성 중에서 주요 독립특성을 추출